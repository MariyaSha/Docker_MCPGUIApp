services:
  # Streamlit GUI aplication 
  ai-app:
    build: .
    volumes:
      - ./:/app
    ports:
      # GUI app accessible in the browser: localhost:8501
      - "8501:8501"
    environment:
    # fetch environment variables from .env
      - BASE_URL
      - MODEL_NAME
      - LOCAL_MCP_HOST
      - REMOTE_MCP_HOST
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      # verify Streamlit app is running with /health endpoint
      test: ["CMD", "curl", "-f", "http://localhost:8501/health"]
    depends_on:
      # Ensure the following services start before ai-app
      - llm
      - gateway-remote
      - gateway-local
  # Communicate with Large Language Model via Docker Model Runner
  llm:
    provider:
      type: model
      options:
        model: ai/qwen2.5
  # Communicate with Local Docker MCP Servers
  gateway-local:
    image: docker/mcp-gateway
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    command:
      - --transport=streaming
      - --port=9011
      # Names of local servers to connect to
      - --servers=duckduckgo
  # Communicate with Remote Docker MCP Servers
  gateway-remote:
    environment:
    - STRIPE_SECRETS
    # - HF_SECRETS
    image: docker/mcp-gateway
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      # copy my custom catalog file into the container
      - ./catalog.yaml:/catalog.yaml  
    command:
      - --transport=streaming
      - --port=8080
      # Names of remote servers to connect to
      - --servers=huggingface
      # Names must map to URLs in catalog.yaml
      - --catalog=/catalog.yaml